---
title: "Ejercicio 1"
output: 
  pdf_document:
    extra_dependencies: ["float"]
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, message = FALSE, warning = FALSE, fig.align = "center",
  fig.pos = "H", out.extra = "", fig.height = 3, fig.width = 4.5
)
colores <- c("#003f5c", "#7a5195", "#ef5675", "#ffa600")
```

```{r}
library(FactoMineR)
library(kableExtra)
library(tidyverse)
library(ggrepel)
library(ape)
source(here::here("src", "utils.R"))
```

## Datos

```{r}
datos <- read_csv2(here::here("data", "raw", "DAMASCO.csv"))
```

Inspeccionamos con `glimpse(datos)`

```{r}
glimpse(datos)
```

**A.** Cuáles son los valores de $n$ y $p$? Cuanto vale y que indica el valor 
$x_{32}$ ? Y el vector $\mathbf{x}_6$ ?

El valor de $n$ es `r nrow(datos)` y el valor de $p$ es `r ncol(datos)`. El
valor de $x_{32}$ es `r datos[[3, 2]]` e indica el tamaño de la flor de la 
observacion 3. El vector $\mathbf{x}_6$ indica la relacion entre el ancho y largo de la 
hoja.

**B.** Cómo clasificaría las variables sobre las que se está trabajando ?

Las variables con las que se esta trabajando son de tipo continuo en todos los 
casos. Mas aun, todas estan medidas en escala de intervalo.

**C.** Encuentre el vector de medias y matriz de varianzas-covariancias 
asociados a la tabla de datos.

Las medias son:

```{r}
datos %>% 
    select(-VAR) %>% 
    summarise_all(mean) %>% 
    round(1) %>% 
    kable() %>% 
    kable_styling(font_size = 12) %>% 
    kable_classic_2()
```

La matriz de covarianza es:

```{r, out.width=.5}
datos %>% 
    select(-VAR) %>%  
    cov() %>%  
    round(1) %>% 
    kable() %>% 
    kable_styling(font_size = 12) %>% 
    kable_classic_2() 
```

**D.** Podría decir cuál y cuáles variables son las más dispersas ?

Utilizando el coeficiente de variación, podemos decir que las variables más 
dispersas, en orden decreciente, son:

```{r}
datos %>% select(-VAR) %>%
    summarise_all(function(x) sd(x) / mean(x)) %>% 
    pivot_longer(cols = everything(), names_to = "VAR", values_to = "CV") %>% 
    arrange(desc(CV)) %>% 
    mutate(CV = round(CV, 1)) %>%
    kable() %>% 
    kable_styling(font_size = 12, full_width = FALSE) %>% 
    kable_classic_2()
```

**E.** Estandarice las variables por media y desvío. Ahora puede responder al 
inciso (d) ?

```{r}
# No utilizamos la primer columna
datos_std = scale(datos[-1])
```

Como son variables estandarizadas, el coeficiente de variacion no existe,
pero todas tienen desvio estandar 1 (ya que la media es 0)

```{r}
datos_std %>%
    as_tibble() %>% 
    summarise_all(function(x) sd(x, na.rm=TRUE) /  mean(x, na.rm=TRUE)) %>% 
    round(1)
```

**F.** Halle la matriz de correlación. Que variables son las más relacionadas?

La matriz de correlación es:

```{r}
datos %>% 
    select(-VAR) %>%
    cor() %>% 
    round(1)  %>% 
    kable() %>% 
    kable_styling(font_size = 12)%>% 
    kable_classic_2()
```

A continuación una representacion grafica de la matriz de correlacion, la cual permite
identificar de forma mas sencilla las variables mas relacionadas:      

```{r}
datos%>%
    select(-VAR) %>%
    cor() %>%
    corrplot::corrplot(
      method = "circle", 
      type = "lower", 
      tl.srt = 15
    )
```

**G.** Pueden dividirse las variables en subgrupos, de modo que las variables 
dentro de un mismo subgrupo tengan elevadas correlaciones entre sí y que las que
se encuentren en subgrupos diferentes tengan bajas correlaciones? Si es así, 
cuáles variables quedan en cada uno de los subgrupos?

* Los subgrupos de variables con altas correlaciones son los siguientes: 

1. Peso, longitud, ancho y espesor del fruto (caracteristicas del fruto)
1. Peso, longitud y ancho del endocarpio (caracteristicas del endocarpio)
1. Tamaño de la flor, longitu y ancho del petalo (caracteristicas de la flor)

* El subgrupo de variables con bajas correlaciones son los siguientes: 

1. Superficie de la hoja, relacion entre peciolo-limbo y relacion entre longitud
y ancho de la hoja (caracteristicas de la hoja); tamaño de la flor, longitud y 
ancho del petalo (caracteristicas de la flor)

Cabe destacar que la superficie de la hoja y relacion peciolo-limbo presentan
correlacion muy baja o nula con cualquiera de las otras variables.

**H.** Encuentre la matriz que mide el grado de similaridad entre las variedades
en función de la distancia euclídea calculada sobre los datos originales.


```{r}
dist <- data.frame(datos[-1])
rownames(dist) <- datos$VAR

matriz_distancia <- dist %>% 
    dist(method = "euclidean", diag = TRUE, upper = TRUE) %>% 
    as.matrix()

 matriz_distancia %>% 
    round(1) %>% 
    kable() %>% 
    kable_styling(latex_options = "HOLD_position") %>% 
    kable_classic_2()
```

**I.** Podría decir cuales son los tres pares de variedades que presentan mayor 
semejanza?

Los pares de variedades que presentan mayor semejanza son:

```{r}
matriz_distancia_df <- data.frame(
  "var1" = rep(colnames(matriz_distancia), each = ncol(matriz_distancia)), 
  "var2" = rep(colnames(matriz_distancia), ncol(matriz_distancia)),
  "distancia" = c(matriz_distancia)
)

matriz_distancia_df %>%
    filter(
      rep(
          1:ncol(matriz_distancia),
          each = ncol(matriz_distancia)
      ) > 
      rep(
          1:ncol(matriz_distancia),
          times = ncol(matriz_distancia)
      )
  ) %>%
  arrange(distancia) %>%
  head(3) %>%
  kable(col.names = c("Variedad 1", "Variedad 2", "Distancia")) %>% 
  kable_styling(font_size = 12, full_width = FALSE) %>% 
  kable_classic_2()
```


**J.** Repita lo realizado en el inciso (h) pero sobre las variables 
estandarizadas por media y desvío estándar. Son las mismas las tres variedades 
más parecidas? Comente al respecto

```{r}
dist_std <- data.frame(scale(datos[-1]))
rownames(dist_std) <- datos$VAR

matriz_distancia_std <- dist_std %>% 
    dist(method = "euclidean", diag = TRUE, upper = TRUE) %>% 
    as.matrix()

matriz_distancia_std %>%
    round(1) %>% 
    kable() %>% 
    kable_styling() %>% 
    kable_classic_2()%>%
    scroll_box(height = "300px", width = "100%")

```

Con los datos estandarizados, los pares de variedades mas parecidas son:

```{r}
matriz_distancia_std_df <- data.frame(
  "var1" = rep(colnames(matriz_distancia_std), each = ncol(matriz_distancia_std)), 
  "var2" = rep(colnames(matriz_distancia_std), ncol(matriz_distancia_std)),
  "distancia" = c(matriz_distancia_std)
)


matriz_distancia_std_df %>%
    filter(
      rep(
          1:ncol(matriz_distancia_std),
          each = ncol(matriz_distancia_std)
      ) > 
      rep(
          1:ncol(matriz_distancia_std),
          times = ncol(matriz_distancia_std)
      )
  ) %>%
  arrange(distancia) %>%
  head(3) %>%
  kable(col.names = c("Variedad 1", "Variedad 2", "Distancia")) %>% 
  kable_styling(font_size = 12, full_width = FALSE) %>% 
  kable_classic_2()

```

Podemos ver que los tres pares de variedades mas parecidas son distintos a los
que vimos en el inciso anterior donde utilizamos los datos sin estandarizar. 
Esto sucede porque las variables estan medidas en diferentes unidades de 
medicion, y al utilizar las variables sin estandarizar se le da mayor peso a 
las que tienen una variabilidad mayor valor en la escala de medida original.

**K.** Mida el grado de concordancia entre ambas matrices de distancia.

```{r}
matriz_distancia_dist <- as.dist(matriz_distancia)
matriz_distancia_std_dist <- as.dist(matriz_distancia_std)
conc <- cor(matriz_distancia_dist, matriz_distancia_std_dist) %>%
      as_tibble() %>%
      round(2) %>%
      rename(CONCORDANCIA = value)
```

El grado de concordancia entre las matrices de distancias es: `r conc `.

A continuacion se realiza una representacion grafica:

```{r}
plot(
  matriz_distancia_dist, 
  matriz_distancia_std_dist, 
  ylab = "Distancias euclideas estandarizadas", 
  xlab = "Distancis euclideas", 
  main = "Concordancia entre las matrices de distancias euclideas"
)
```

**L.** Realice un Análisis de Componentes Principales utilizando de la matriz de
correlaciones.

Los autovalores obtenidos son los siguientes:

```{r}
datos_std <- data.frame(datos_std)
rownames(datos_std) <- datos$VAR

pca <- PCA(datos_std, ncp = 2, graph = FALSE)

pca$eig %>%
  data.frame() %>%
  rename(
    "Autovalores" = "eigenvalue", 
    "% Varianza" = "percentage.of.variance", 
    "% Varianza acumulada" = "cumulative.percentage.of.variance" 
  ) %>%
  kable() %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2()
```

Tambien pueden observarse graficamente: 

```{r}
# Agregar linea que acumula.
prop_table = prop.table(pca$eig[, 1])
barplot(prop_table, main = "AUTOVALORES", names.arg = 1:nrow(pca$eig))
#lines(c(1, 13), c(0, 0.5))
```

Y los autovectores (cargas asociadas a cada componente) son: 

```{r}
pca$var$coord %>%
  kable() %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2()
```

**M.** Analice los porcentaje de variabilidad explicada por los primeros ejes 
principales.

Observando los autovalores y el porcentaje de varianza explicada de cada uno, 
podemos decir que la primer componente explica el `r round(pca$eig[1, 2], 2)`%, 
mientras que la segunda componente explica `r round(pca$eig[2, 2], 2)`%. Luego, 
la varianza total explicada por estas dos componentes es 
`r round(pca$eig[2, 3], 2)`%.

**N.** Establezca intuitivamente grupos de variedades similares según su 
cercanía en el plano principal.

A continuacion se presenta la representacion grafica de las variedades en el 
plano principal:

```{r, fig.width = 6, fig.height=4}

pc1 <- pca$ind$coord[, 1]
pc2 <- pca$ind$coord[, 2]
etiquetas <- rownames(pca$ind$coord)
datos_cp<-as.data.frame(cbind(etiquetas, pc1, pc2))
colnames(datos_cp) <- c("VARIEDAD","CP1", "CP2")
#datos_CP$etiqueta <- datos$Var
#datos_CP$variedad <- substr(datos_CP$etiqueta, 1, 1)


ggplot(datos_cp) + 
  geom_point(aes(pc1, pc2), size = 4, color = "gray30") + 
  geom_label_repel(aes(pc1, pc2, label = VARIEDAD)) + 
  geom_vline(xintercept = 0, linetype = "solid") + 
  geom_hline(yintercept = 0, linetype = "solid") + 
  labs(
    x = "Coordenada Principal 1",
    y = "Coordenada Principal 2"
  )

```

Tras observar el grafico podemos decir que encontramos cuatro grupos. 
El primer grupo contiene a MARTINET, CANINO.T y BLANCO. El segundo esta 
conformado por CANINO y TADEO. El tercer grupo esta conformado solamente por 
GABACHET, que se diferencia de todas las variedades. Y el cuarto grupo que se 
compone por el resto de las variedades, que estan ubicadas alrededor del 
comportamiento promedio, es decir, el origen del plano.

**O.** Encuentre e interprete gradientes de las variables originales en el plano
principal en función de sus cargas sobre las dos primeras componentes.

Observando nuevamente las coordenadas de las variables(autovectores):
```{r}
pca$var$coord %>%
  kable() %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 
```
Considerando la primer componente, los damascos que tengan flores, frutos y endocarpio grandes
se van a ubicar a la derecha del grafico

Con respecto a la segunda componente, los damoscos cuyas hojas sean grandes estarán ubicados en 
la parte superior del grafico, lo mismo ocurre con aquellos damascos con flores grandes. Los damascos
que tengan frutos pequeños, estaran ubicados en la parte inferior del grafico. 

Luego:

   * Damascos con hojas grandes estaran ubicados en el segundo cuadrante del grafico.
   * Damascos con endocarpio y frutos grandes estaran ubicados en el cuarto cuadrante del grafico
   * Damascos con flores grandes estaran ubicados en el primer cuadrante del grafico
   


**P.** Caracterice los grupos determinados en el inciso (N) según los gradientes
descriptos en (O).

Grupo 1: es un grupo de variedades caracterizadas por tener flores, endocarpio y
hojas grandes y frutos medianos.

Grupo 2: es un grupo caracterizado por tener endoncarpio grande, frutos grandes,
hojas pequeñas y flores medianas

Grupo 3: es un fruto caracterizado por tener hojas grandes, frutos y endocarpio
pequeños y flores medianas. 


**Q.** Superponga en la representación del plano principal un MST. Comente al 
respecto, haría algún reagrupamiento ?

```{r}
library(vegan)
```

```{r}
mst <- spantree(matriz_distancia_std_dist)
plot(mst, pca$ind$coord)
# faltan las cp!
```


**R.** Con el software `R` realice el ACP recurriendo a operaciones con 
matrices (decomposición espectral)

Realizando la descomposicion espectral, los autovalores son los siguientes:

```{r}
x <- as.matrix(datos_std)
cor <- cor(x)
autovalores_ <- eigen(cor)

round(autovalores_$values, 1) %>%
  kable(col.names = "AUTOVALORES") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 
```

Y los autovectores:

```{r}
round(autovalores_$vectors[, 1:2], 1) %>%
  kable(col.names = c("AUTOVECTOR 1", "AUTOVECTOR 2")) %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2()
```

Las nuevas coordenadas de las variedades sobre las componentes halladas:

```{r}
etiquetas <- rownames(pca$var$coord)
p <- as.matrix(autovalores_$vectors)
y <- x %*% p
colnames(y) <- etiquetas
rownames(y) <- datos$VAR

round(y, 1) %>%
  kable() %>%
  kable_classic_2()
```

**S.**  Verifique que con el enfoque Biplot (DVS) llega a los mismos resultados

Valores singulares (d):

```{r}
dvs <- svd(x)

round(dvs$d, 1) %>%
  kable(col.names = "d")%>%
  kable_styling(full_width = FALSE)%>%
  kable_classic_2()
```


Vectores singulares por izquierda (u):

```{r}
colnames(dvs$u) <- etiquetas

dvs$u %>%
  round(1) %>%
  kable() %>%
  kable_classic_2()
```

Vectores singulares por derecha (v):

```{r}
colnames(dvs$v) <- etiquetas

dvs$v %>%
  round(1) %>%
  kable() %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2()
```

Las nuevas cordenadas de las variedades halladas a traves de DVS:

```{r}
u <- dvs$u
v <- dvs$v
d <- diag(dvs$d, 13, 13)
ydvs <- u %*% d
colnames(ydvs) <- etiquetas
rownames(ydvs) <- datos$VAR

round(ydvs, 1) %>%
  kable() %>%
  kable_classic_2()
```


**FALTA VERIFICAR QUE SE LLEGA AL MISMO RESULTADO**


Graficos de variedades en plano de 2 componentes encimados.
Como hago para encimar en ggplot2??
```{r}



```

**T.** Obtenga 4 dendogramas ultramétricos según diferentes criterios de 
encadenamiento (SIMPLE, COMPUESTO, UPGMA y WARD).

Criterio de encadenamiento Simple:
```{r, fig.height=5, fig.width=10, class.source = 'fold-hide'}

cluster_min <- hclust(matriz_distancia_std_dist, method = "single")
cluster_min_data<- dendro_data_k(cluster_min, k=4)

ggplot(cluster_min_data$segments) + 
  geom_segment(
    aes(x = x, y = y, xend = xend, yend = yend, color = as.factor(clust)),
    size = 1.2,
    lineend = "round"
  ) + 
  geom_text(
    aes(x = x, y = y - 0.40, label = label, color = as.factor(clust)), 
    data = cluster_min_data$labels
  ) + 
  coord_flip() + 
  labs(
    y = "Distancia"
  ) + 
  scale_colour_manual(
    values = c("grey30", scales::hue_pal()(4))
  ) + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.title.x = element_text(size = 14), 
    axis.title.y = element_blank(), 
    axis.text.x = element_text(size = 12),
    axis.text.y = element_blank(), 
    axis.line = element_blank(), 
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )


```




 
Criterio de encadenamiento Compuesto:
```{r, fig.height=5, fig.width=10, class.source = 'fold-hide'}
cluster_com <- hclust(matriz_distancia_std_dist, method = "complete")
cluster_com_data<- dendro_data_k(cluster_com, k=4)

ggplot(cluster_com_data$segments) + 
  geom_segment(
    aes(x = x, y = y, xend = xend, yend = yend, color = as.factor(clust)),
    size = 1.2,
    lineend = "round"
  ) + 
  geom_text(
    aes(x = x, y = y - 0.40, label = label, color = as.factor(clust)), 
    data = cluster_com_data$labels
  ) + 
  coord_flip() + 
  labs(
    y = "Distancia"
  ) + 
  scale_colour_manual(
    values = c("grey30", scales::hue_pal()(4))
  ) + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.title.x = element_text(size = 14), 
    axis.title.y = element_blank(), 
    axis.text.x = element_text(size = 12),
    axis.text.y = element_blank(), 
    axis.line = element_blank(), 
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )



```

Criterio de encadenamiento UPGMA
```{r, fig.height=5, fig.width=10, class.source = 'fold-hide'}
cluster_upgma <- hclust(matriz_distancia_std_dist, method = "average")
cluster_upgma_data<- dendro_data_k(cluster_upgma, k=4)

ggplot(cluster_upgma_data$segments) + 
  geom_segment(
    aes(x = x, y = y, xend = xend, yend = yend, color = as.factor(clust)),
    size = 1.2,
    lineend = "round"
  ) + 
  geom_text(
    aes(x = x, y = y - 0.40, label = label, color = as.factor(clust)), 
    data = cluster_upgma_data$labels
  ) + 
  coord_flip() + 
  labs(
    y = "Distancia"
  ) + 
  scale_colour_manual(
    values = c("grey30", scales::hue_pal()(4))
  ) + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.title.x = element_text(size = 14), 
    axis.title.y = element_blank(), 
    axis.text.x = element_text(size = 12),
    axis.text.y = element_blank(), 
    axis.line = element_blank(), 
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )
 

```

Criterio de encadenamiento WARD

```{r, fig.height=5, fig.width=10}
cluster_ward <- hclust(matriz_distancia_std_dist, method = "ward.D")
cluster_ward_data<- dendro_data_k(cluster_ward, k=4)

ggplot(cluster_ward_data$segments) + 
  geom_segment(
    aes(x = x, y = y, xend = xend, yend = yend, color = as.factor(clust)),
    size = 1.2,
    lineend = "round"
  ) + 
  geom_text(
    aes(x = x, y = y - 2, label = label, color = as.factor(clust)), 
    data = cluster_ward_data$labels
  ) + 
  coord_flip() + 
  ylim(-5, 20) + 
  labs(
    y = "Distancia"
  ) + 
  scale_colour_manual(
    values = c("grey30", scales::hue_pal()(4))
  ) + 
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    panel.background = element_blank(),
    axis.title.x = element_text(size = 14), 
    axis.title.y = element_blank(), 
    axis.text.x = element_text(size = 12),
    axis.text.y = element_blank(), 
    axis.line = element_blank(), 
    axis.ticks.y = element_blank(),
    plot.title = element_text(hjust = 0.5),
    legend.position = "none"
  )


```


**U.** Asocie a cada uno de los árboles obtenidos en el inciso anterior la 
matriz cofenética correspondiente. Que miden los elementos de estas matrices ?

Encadenamiento Simple:
```{r}
cophenetic_min = cophenetic(cluster_min)
min_data<-as.data.frame(cbind(matriz_distancia_std_dist, cophenetic_min))

ggplot(min_data) +
  geom_point(aes(cophenetic_min,matriz_distancia_std_dist ))+
  theme_classic()+
  labs(x="Cophenetic - Simple", y ="Distancias Estandarizadas")
```


Encadenamiento Compuesto:
```{r}
cophenetic_comp <- cophenetic(cluster_com)
comp_data<-as.data.frame(cbind(matriz_distancia_std_dist, cophenetic_comp))

ggplot(comp_data) +
  geom_point(aes(cophenetic_comp,matriz_distancia_std_dist ))+
  theme_classic()+
  labs(x="Cophenetic - Compuesto", y ="Distancias Estandarizadas")
```


Encadenamiento UPGMA:
```{r}
cophenetic_upgma = cophenetic(cluster_upgma)
upgma_data<-as.data.frame(cbind(matriz_distancia_std_dist, cophenetic_upgma))

ggplot(upgma_data) +
  geom_point(aes(cophenetic_upgma,matriz_distancia_std_dist ))+
  theme_classic()+
  labs(x="Cophenetic - UPGMA", y ="Distancias Estandarizadas")
```


Encadenamiento WARD:
```{r}
cophenetic_ward = cophenetic(cluster_ward)
ward_data<-as.data.frame(cbind(matriz_distancia_std_dist, cophenetic_ward))

ggplot(ward_data) +
  geom_point(aes(cophenetic_ward,matriz_distancia_std_dist ))+
  theme_classic()+
  labs(x="Cophenetic - WARD", y ="Distancias Estandarizadas")
```

Los elementos de las matrices anteriores permiten tener una medida de la 
coherencia del criterio de agrupamiento jerarquico

**V.** Cuantifique la concordancia entre la matriz de distancia que dio origen 
a los dendogramas y las 4 matrices cofenéticas. A que conclusión llega ?


Encadenamiento simple
```{r}
corcof_min<-cor(cophenetic_min, matriz_distancia_std_dist)

round(corcof_min, 2) %>%
  kable(align = "c", col.names = "Correlacion") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 
```


Encadenamiento Compuesto
```{r}
corcof_com<-cor(cophenetic_comp, matriz_distancia_std_dist)

round(corcof_com, 2) %>%
  kable(align = "c", col.names = "Correlacion") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 

```


Encadenamiento UPGMA
```{r}
corcof_upgma<-cor(cophenetic_upgma, matriz_distancia_std_dist)

round(corcof_upgma, 2) %>%
  kable(align = "c", col.names = "Correlacion") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 
```


Encadenamiento WARD
```{r}
corcof_ward<-cor(cophenetic_ward, matriz_distancia_std_dist)

round(corcof_ward, 2) %>%
  kable(align = "c", col.names = "Correlacion") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 
```

Observando las correlaciones obtenidas entre la matriz de distancia y las diferentes matrices cofeneticas puede decirse que la obtenida a traves del metodo de encadenamiento UPGMA es la mas alta
QUE MAS??

**W.** Existe algún punto de corte sobre el índice de jerarquización del 
dendograma UPGMA que origine los mismos agrupamiento de variedades obtenidos en 
Análisis de Componentes Principales ?

```{r}
grupos<-cutree(cluster_upgma, k=6)
plot(cluster_upgma, main = " ")
rect.hclust(cluster_upgma, k=6, border = "RED")
```

**X.** Mida el grado de concordancia entre los resultados obtenidos por 
Componentes y por Cluster UPGMA

????
```{r}

dist_pca<-dist(pca$ind$coord, method="euclidean")
cor(dist_pca, cophenetic_upgma)%>%
  round(2)%>%
  kable(align = "c") %>%
  kable_styling(full_width = FALSE) %>%
  kable_classic_2() 

```

**Y.** Halle el dendograma aditivo Neighbor Joining, representa mejor la 
configuración de variedades que el Cluster UPGMA ?

```{r}

nj<-nj(matriz_distancia_std_dist)
plot(nj, "u")
# usar funcion 'nj'
```
